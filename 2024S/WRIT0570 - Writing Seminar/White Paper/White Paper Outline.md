---
date: 2024-02-26
type: note
tags: 
---

**Target audience:** chip makers, startups, venture capital investors, climate-aware individuals curious about AI impacts on climate

**Keywords:** AI carbon emissions, Moore's Law, Dennard's Scaling, Semiconductors, Biocomputing, Neuromorphic Computing

**Introduction**
- Premise
	- Background of how AI came to start, and the meteoric rise of AI after the release of GPT. Go over OpenAI as a company.
	- Background of how AI is trained (simply) and what that means (data centers, electricity, etc)
- Proposition
	- The world needs a solution to solve the increasing energy demands of AI if we are to have a sustainable future.
- Rationale/Significance
	- If we don't, we will all die from irreversible global climate change.

**Problem**
- Increased AI usage is going to rapidly increase global energy demands
	- Show carbon emissions scale (projection of tons emitted and provide examples)
	- Show calculations and projections (image) of global energy demands increase (1-2% to 8-21%)
- Ultimately: current progress and adoption of AI training and deployment is unsustainable.
- People are attempting to tackle these problems in 2 methods, but they are both riddled with problems as well.
1. Increasing overall energy supply (nuclear fusion, solar energy) - problem is the adoption and rate of innovation is too slow for current AI deployments
	- Talk about Helion (nuclear fusion) and solar energy panel companies and discuss about their rate of innovation and when scale will happen
2. Making software more efficient for AI - that's not likely to happen as companies compete for the greatest and bestest model, and the sheer amount of AI being trained still results in massive carbon emissions
	- Compare OpenAI, Google, Mistral models and showcase the increasing parameter size and complexity of progressing generational models

**Solutions**
- The only viable solution is to make the hardware more efficient
1. Talk about Nvidia, Google, and AMD building faster GPUs for AI, but they still consume massive amounts of energy and are facing the Dennard's scaling and Moore's law slowdown.
2. Talk about the new chip design called neuromorphic chips that is being developed by Intel (Loihi) and IBM (TrueNorth) chips. And describe their benefits over traditional silicon chips (energy efficient) - but the problem remains that they relies on silicon, which is approaching a shortage
3. Talk about biocomputing and biologics-based computing paradigm. Introduce cortical labs, rain neuromorphic, and Nanoneuro Systems.
	- Brain energy and performance efficiencies, and also the bypassing of the silicon bottleneck

**Conclusions**
- The immediate and necessary path forwards is the development of more energy-efficient chips, which most likely will happen through a shift towards biologics-based computing.
- The long term path will be to continue the development of clean energy sources like nuclear fission and fusion, solar, and wind energies, which will hopefully be viable at scale in 20 years.